{"name": "tonioo_sievelib_Lexer.scan", "language": "py", "prompt": "def scan(self, text):\n        \"\"\"Analyse some data\n\n        Analyse the passed content. Each time a token is recognized, a\n        2-uple containing its name and parsed value is raised (via\n        yield).\n\n        On error, a ParseError value is raised.\n\n        :param text: a text string containing the command to parse\n        \"\"\"", "tests": "", "completions": ["\n        self.setup()\n        for i, token in enumerate(self._scan(text)):\n            yield token\n        self.finish()\n\n    def _scan(self, text):\n        \"\"\"Analyse some data\n\n        Analyse the passed content. Each time a token is recognized, a\n        2-uple containing its name and parsed value is raised (via\n        yield).\n\n        On error, a ParseError value is raised.\n\n        :param text: a text string containing the command to parse\n        \"\"\"\n        raise NotImplementedError()\n"], "stop_tokens": ["\ndef", "\n#", "\nif", "\nclass"], "tokens": [], "softmax": []}